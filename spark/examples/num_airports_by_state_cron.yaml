apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: ScheduledSparkApplication
metadata:
  name: op-num-airports-by-state-cron
  namespace: default
spec:
  #schedule: "@every 5m"
  schedule: "*/5 * * * *"
  concurrencyPolicy: Allow
  suspend: false
  successfulRunHistoryLimit: 2
  failedRunHistoryLimit: 3
  template:
    type: Scala
    mode: cluster
    image: "iad.ocir.io/ochacafens/ochacafe/spark:3.2.0"
    imagePullPolicy: Always
    imagePullSecrets: 
      - docker-registry-secret
    mainClass: com.example.demo.NumAirportsByState
    mainApplicationFile: "oci://spark@ochacafens/lib/us-flights-app_2.12-0.1.jar"
    arguments: 
      - "--input_file"
      - "oci://spark@ochacafens/data/airports.csv"
      - "--output_file"
      - "oci://spark@ochacafens/out/num_airports_by_state"
    sparkVersion: "3.2.0"
    restartPolicy:
      type: Never
    sparkConf:
      spark.sql.hive.metastore.sharedPrefixes: shaded.oracle,com.oracle.bmc
      spark.hadoop.fs.oci.client.hostname: "https://objectstorage.us-ashburn-1.oraclecloud.com"
      spark.hadoop.fs.oci.client.custom.authenticator: "com.oracle.bmc.hdfs.auth.InstancePrincipalsCustomAuthenticator"
      spark.eventLog.enabled: "true"
      spark.eventLog.dir: "oci://spark@ochacafens/history"
    timeToLiveSeconds: 3600
    nodeSelector:
      name: "pool2"
    driver:
      cores: 2
      coreLimit: "3000m"
      memory: "2g"
      labels:
        version: 3.2.0
      serviceAccount: spark
    executor:
      cores: 1
      instances: 3
      memory: "512m"
      labels:
        version: 3.2.0
